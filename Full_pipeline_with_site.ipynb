{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ronyavivi/PhotoBombFix/blob/main/Full_pipeline_with_site.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMIHaWS39Nzb"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_iHs_wm2Mhh"
      },
      "source": [
        "## Credits : \n",
        "https://colab.research.google.com/github/tensorflow/tpu/blob/master/models/official/mask_rcnn/mask_rcnn_demo.ipynb#scrollTo=DL_0tSC67biu\n",
        "\n",
        "https://github.com/tensorflow/models/blob/master/research/object_detection/utils/visualization_utils.py\n",
        "\n",
        "https://advimman.github.io/lama-project/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Website link : https://3e6u7yt7fdew4msm.anvil.app/4AKYTHGA6YHKTACKEAUX5KF3"
      ],
      "metadata": {
        "id": "4QYhSbw7FVcX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##About :\n",
        "\n",
        "This is the final notebook tha works with the site. due to gpu the second part doen't works with the site. \n",
        "\n",
        "You can get your prediction by going to : \"Manually run the final step\" box, enter the bomber number and run the next 2 cells. \n",
        "\n",
        "<br> In order to run the notebook in another drive change this path wherever you see it :\n",
        "<br> '/content/gdrive/My Drive/Colab_Notebooks/Final_project'\n",
        "<br> you will find all the locations to change by pressing ctrl+f and search \"to_change\".\n",
        "<br><br> **The notebook will work only with sufficient GPU. **\n",
        "\n",
        "##About the site \n",
        "\n",
        "\n",
        "*   First part of segmentation works and you can use it :)\n",
        "*   Second part of inpainting only work after running the code manually and adding the inpainted image to the output folder.\n",
        "\n"
      ],
      "metadata": {
        "id": "JCdTnHRyDiHH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODxpKwkNFrBk"
      },
      "source": [
        "## Download the source code\n",
        "Download the source code of the Mask R-CNN model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUaCGBUQFgiq"
      },
      "outputs": [],
      "source": [
        " !git clone https://github.com/tensorflow/tpu/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcvdDRxnQJ-j"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/tensorflow/models/tree/master/research/object_detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPbB7s8hPHfO"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EtGbyNc8VgS"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/tensorflow/models/blob/master/research/object_detection/utils/visualization_utils.py\n",
        "from IPython import display\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "sys.path.insert(0, 'tpu/models/official')\n",
        "sys.path.insert(0, 'tpu/models/official/mask_rcnn')\n",
        "import coco_metric\n",
        "import collections\n",
        "import six\n",
        "from mask_rcnn.object_detection import visualization_utils\n",
        "from mask_rcnn.object_detection import shape_utils\n",
        "import cv2\n",
        "import base64\n",
        "import numpy as np\n",
        "import os\n",
        "from shutil import copyfile\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtS2N5EbtuME"
      },
      "outputs": [],
      "source": [
        "# mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vksDaFMuCdN"
      },
      "outputs": [],
      "source": [
        "import sys \n",
        "sys.path.insert(0,'/content/gdrive/My Drive/Colab_Notebooks/Final_project')##to_change"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2ANV0wouEtM"
      },
      "outputs": [],
      "source": [
        "os.chdir('/content/gdrive/MyDrive/Colab_Notebooks/Final_project') ##to_change"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1bmadaDs6IE"
      },
      "outputs": [],
      "source": [
        "import visualization_utils_adjusted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkTSG22ePKkz"
      },
      "source": [
        "## Load the COCO index mapping\n",
        "This Colab uses a pretrained checkpoint of the Mask R-CNN model that is trained using the COCO dataset. Here is the mapping between the indices that the model predicts and the categories in text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Q5r1zob93OF"
      },
      "outputs": [],
      "source": [
        "ID_MAPPING = {\n",
        "    1: 'person',\n",
        "    2: 'bicycle',\n",
        "    3: 'car',\n",
        "    4: 'motorcycle',\n",
        "    5: 'airplane',\n",
        "    6: 'bus',\n",
        "    7: 'train',\n",
        "    8: 'truck',\n",
        "    9: 'boat',\n",
        "    10: 'traffic light',\n",
        "    11: 'fire hydrant',\n",
        "    13: 'stop sign',\n",
        "    14: 'parking meter',\n",
        "    15: 'bench',\n",
        "    16: 'bird',\n",
        "    17: 'cat',\n",
        "    18: 'dog',\n",
        "    19: 'horse',\n",
        "    20: 'sheep',\n",
        "    21: 'cow',\n",
        "    22: 'elephant',\n",
        "    23: 'bear',\n",
        "    24: 'zebra',\n",
        "    25: 'giraffe',\n",
        "    27: 'backpack',\n",
        "    28: 'umbrella',\n",
        "    31: 'handbag',\n",
        "    32: 'tie',\n",
        "    33: 'suitcase',\n",
        "    34: 'frisbee',\n",
        "    35: 'skis',\n",
        "    36: 'snowboard',\n",
        "    37: 'sports ball',\n",
        "    38: 'kite',\n",
        "    39: 'baseball bat',\n",
        "    40: 'baseball glove',\n",
        "    41: 'skateboard',\n",
        "    42: 'surfboard',\n",
        "    43: 'tennis racket',\n",
        "    44: 'bottle',\n",
        "    46: 'wine glass',\n",
        "    47: 'cup',\n",
        "    48: 'fork',\n",
        "    49: 'knife',\n",
        "    50: 'spoon',\n",
        "    51: 'bowl',\n",
        "    52: 'banana',\n",
        "    53: 'apple',\n",
        "    54: 'sandwich',\n",
        "    55: 'orange',\n",
        "    56: 'broccoli',\n",
        "    57: 'carrot',\n",
        "    58: 'hot dog',\n",
        "    59: 'pizza',\n",
        "    60: 'donut',\n",
        "    61: 'cake',\n",
        "    62: 'chair',\n",
        "    63: 'couch',\n",
        "    64: 'potted plant',\n",
        "    65: 'bed',\n",
        "    67: 'dining table',\n",
        "    70: 'toilet',\n",
        "    72: 'tv',\n",
        "    73: 'laptop',\n",
        "    74: 'mouse',\n",
        "    75: 'remote',\n",
        "    76: 'keyboard',\n",
        "    77: 'cell phone',\n",
        "    78: 'microwave',\n",
        "    79: 'oven',\n",
        "    80: 'toaster',\n",
        "    81: 'sink',\n",
        "    82: 'refrigerator',\n",
        "    84: 'book',\n",
        "    85: 'clock',\n",
        "    86: 'vase',\n",
        "    87: 'scissors',\n",
        "    88: 'teddy bear',\n",
        "    89: 'hair drier',\n",
        "    90: 'toothbrush',\n",
        "}\n",
        "category_index = {k: {'id': k, 'name': ID_MAPPING[k]} for k in ID_MAPPING}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HngQNsyjXmvF"
      },
      "source": [
        "## Load an image\n",
        "Now, you can load an image. Use either the sample image included here, or update the field with an image of your choice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwrFI4C9Vvam"
      },
      "source": [
        "## Create a Tensorflow session\n",
        "Now let us create a Tensorflow session to run the inference. You can either connect to a TPU or a normal CPU backend."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install anvil-uplink\n",
        "import anvil.server\n",
        "\n",
        "anvil.server.connect(\"server_2BAUIPXF2NECUCB2PLF6DJF4-3E6U7YT7FDEW4MSM\")"
      ],
      "metadata": {
        "id": "pTB40DAI-jmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEJ1Ow8c1hYA"
      },
      "source": [
        "# Prepare a full pipeline function to connect to the server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNpo1H7oQ8oh"
      },
      "outputs": [],
      "source": [
        "##function 1 - get image\n",
        "import io\n",
        "from PIL import Image\n",
        "\n",
        "@anvil.server.callable\n",
        "def get_image(img):\n",
        "  os.chdir('/content/gdrive/MyDrive/Colab_Notebooks/Final_project') ##to_change\n",
        "  shutil.rmtree('./data_for_prediction', ignore_errors=True)\n",
        "  os.mkdir('./data_for_prediction')\n",
        "  img = Image.open(io.BytesIO(img.get_bytes()))\n",
        "  img.save('./data_for_prediction/test.jpg')\n",
        "  return \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGhXXMWQORhu"
      },
      "outputs": [],
      "source": [
        "##function 2 - get image segmentation\n",
        "import json \n",
        "import pickle\n",
        "\n",
        "@anvil.server.callable\n",
        "def get_segmentation() :\n",
        "  os.chdir('/content/gdrive/MyDrive/Colab_Notebooks/Final_project') ##to_change\n",
        "  session = tf.compat.v1.Session(graph=tf.Graph())  \n",
        "  #open image\n",
        "  image_path = '/content/gdrive/MyDrive/Colab_Notebooks/Final_project/data_for_prediction/test.jpg'##to_change\n",
        "  with open(image_path, 'rb') as f:\n",
        "    np_image_string = np.array([f.read()])\n",
        "  image = Image.open(image_path)\n",
        "  width, height = image.size\n",
        "  h = height\n",
        "  file = open('height_file.txt', 'wb')\n",
        "  pickle.dump(h, file)\n",
        "  file.close()\n",
        "  w = width\n",
        "  file = open('width_file.txt', 'wb')\n",
        "  pickle.dump(w, file)\n",
        "  file.close()\n",
        "\n",
        "  #get model\n",
        "  np_image = np.array(image.getdata()).reshape(height, width, 3).astype(np.uint8)\n",
        "  saved_model_dir = 'gs://cloud-tpu-checkpoints/mask-rcnn/1555659850' \n",
        "  _ = tf.compat.v1.saved_model.load(session, ['serve'], saved_model_dir)\n",
        "  feed_dict = {}\n",
        "\n",
        "  #get prediction\n",
        "  global segmentations\n",
        "  global detection_boxes\n",
        "  with session as session:\n",
        "    num_detections, detection_boxes, detection_classes, detection_scores, detection_masks, image_info = session.run(\n",
        "        ['NumDetections:0', 'DetectionBoxes:0', 'DetectionClasses:0', 'DetectionScores:0', 'DetectionMasks:0', 'ImageInfo:0'],\n",
        "        feed_dict={'Placeholder:0': np_image_string})\n",
        "    \n",
        "  #edit prediction\n",
        "  detection_classes=detection_classes.astype(np.int32)\n",
        "  num = int(num_detections)\n",
        "  to_be_removed = []\n",
        "  for i in range(num) :\n",
        "    if detection_classes[0][i] != 1:\n",
        "      to_be_removed.append(i)\n",
        "  to_be_removed.sort(reverse = True)\n",
        "  for t in to_be_removed : \n",
        "    detection_classes = np.delete(detection_classes , t , axis = 1)\n",
        "    detection_scores = np.delete(detection_scores , t , axis = 1)\n",
        "    detection_boxes = np.delete(detection_boxes , t , axis = 1)\n",
        "    detection_masks = np.delete(detection_masks , t , axis = 1)\n",
        "  num_detections = (detection_classes.shape)[1]\n",
        "  detection_boxes = np.squeeze(detection_boxes * image_info[0, 2], axis=(0,))[0:num_detections]\n",
        "  detection_scores = np.squeeze(detection_scores, axis=(0,))[0:num_detections]\n",
        "  detection_classes = np.squeeze(detection_classes.astype(np.int32), axis=(0,))[0:num_detections]\n",
        "  instance_masks = np.squeeze(detection_masks, axis=(0,))[0:num_detections]\n",
        "  ymin, xmin, ymax, xmax = np.split(detection_boxes, 4, axis=-1)\n",
        "  processed_boxes = np.concatenate([xmin, ymin, xmax - xmin, ymax - ymin], axis=-1)\n",
        "  segmentations = coco_metric.generate_segmentation_from_masks(instance_masks, processed_boxes, height, width)\n",
        "\n",
        "  #Diaplay detections on image : \n",
        "  max_boxes_to_draw = 30 \n",
        "  image_with_detections = visualization_utils_adjusted.visualize_boxes_and_labels_on_image_array(\n",
        "      np_image,\n",
        "      detection_boxes,\n",
        "      detection_classes,\n",
        "      detection_scores,\n",
        "      category_index,\n",
        "      instance_masks=segmentations,\n",
        "      use_normalized_coordinates=False,\n",
        "      max_boxes_to_draw=max_boxes_to_draw)\n",
        "\n",
        "  image_with_detections = Image.fromarray(image_with_detections.astype(np.uint8))\n",
        "  image_with_detections.save('/content/gdrive/MyDrive/Colab_Notebooks/Final_project/data_for_prediction/image_with_detections.png')##to_change\n",
        "  b = io.BytesIO()\n",
        "  image_with_detections.save(b, 'jpeg')\n",
        "  im_bytes = b.getvalue()\n",
        "  return anvil.BlobMedia(\"image/jpg\",im_bytes)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjHuO49maf6R"
      },
      "source": [
        "## Perform instance segmentation and retrieve the predictions\n",
        "Now let's run the inference and process the predictions from the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZ3DdlhVSYvY"
      },
      "outputs": [],
      "source": [
        "def create_mask(height,width,segmentations,b):\n",
        "    image_data = np.zeros((height, width), dtype=np.uint8)\n",
        "\n",
        "    for row in range(segmentations[b].shape[0]): \n",
        "        for col in range(segmentations[b].shape[1]):\n",
        "            if segmentations[b][row][col] == 1 : \n",
        "                image_data[row][col] = 255\n",
        "                # Add pixels to the left of the mask\n",
        "                if col >= 11:\n",
        "                    image_data[row][col-11] = 255\n",
        "                else:\n",
        "                    image_data[row][:col] = 255\n",
        "                # Add pixels to the right of the mask\n",
        "                if col <= width-12:\n",
        "                    image_data[row][col+11] = 255\n",
        "                else:\n",
        "                    image_data[row][col:] = 255\n",
        "                # Add pixels to the top of the mask\n",
        "                if row >= 11:\n",
        "                    image_data[row-11][col] = 255\n",
        "                else:\n",
        "                    image_data[:row,col] = 255\n",
        "                # Add pixels to the bottom of the mask\n",
        "                if row <= height-12:\n",
        "                    image_data[row+11][col] = 255\n",
        "                else:\n",
        "                    image_data[row:,col] = 255\n",
        "    return image_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adkJ079RQ02U"
      },
      "outputs": [],
      "source": [
        "##function 3 - create mask\n",
        "from IPython.display import display\n",
        "bomber = 1\n",
        "\n",
        "@anvil.server.callable\n",
        "def create_cur_mask (bomber) : \n",
        "  print(os.getcwd())\n",
        "  b = int(bomber) - 1\n",
        "  file = open('height_file.txt', 'rb')\n",
        "  height = pickle.load(file)\n",
        "  file.close()\n",
        "  file = open('width_file.txt', 'rb')\n",
        "  width = pickle.load(file)\n",
        "  file.close()\n",
        "  os.remove('width_file.txt')\n",
        "  os.remove('height_file.txt')\n",
        "  cur_mask = create_mask(height, width ,segmentations,b)\n",
        "  cur_mask = Image.fromarray(cur_mask)\n",
        "  cur_mask.save('/content/gdrive/MyDrive/Colab_Notebooks/Final_project/data_for_prediction/test_mask.png')##to_change\n",
        "\n",
        "  return ()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Fq51D-NjaUM"
      },
      "source": [
        "Add wait_forever for the server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsrpbVp5drX1"
      },
      "outputs": [],
      "source": [
        "## imports for the second part : \n",
        "print('\\n> Cloning the repo')\n",
        "!git clone https://github.com/advimman/lama.git\n",
        "\n",
        "print('\\n> Install dependencies')\n",
        "!pip install torch==1.8.0 torchvision==0.9.0 torchaudio==0.8.0 torchtext==0.9\n",
        "!pip install -r lama/requirements.txt --quiet\n",
        "!pip install wget --quiet\n",
        "!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html --quiet\n",
        "\n",
        "\n",
        "print('\\n> Changing the dir to:')\n",
        "os.chdir('/content/gdrive/MyDrive/Colab_Notebooks/Final_project/lama')##to_change \n",
        "\n",
        "print('\\n> Download the model')\n",
        "!curl -L $(yadisk-direct https://disk.yandex.ru/d/ouP6l8VJ0HpMZg) -o big-lama.zip\n",
        "!unzip big-lama.zip\n",
        "\n",
        "print('>fixing opencv')\n",
        "!pip uninstall opencv-python-headless -y --quiet\n",
        "!pip install opencv-python-headless==4.1.2.30 --quiet\n",
        "\n",
        "\n",
        "print('\\n> Init mask-drawing code')\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from shutil import copyfile\n",
        "# import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-gpu==2.7.0+nv21.9 tensorflow-gpu-estimator==2.7.0\n",
        "!pip install scikit-learn>=1.0.0\n"
      ],
      "metadata": {
        "id": "4_bhQZAdGi2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3fkXxtRXx6p"
      },
      "outputs": [],
      "source": [
        "## function 4 - erase and inpaint : \n",
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "@anvil.server.callable\n",
        "def get_new_image():\n",
        "  inpainted_path = '/content/gdrive/MyDrive/Colab_Notebooks/Final_project/output/test_mask.png'\n",
        "  #inpainted_path = os.path.join('/content/output', 'test_mask.png')\n",
        "  inpainted = np.array(Image.open(inpainted_path).convert('RGB'))\n",
        "  inpainted = Image.fromarray(inpainted.astype(np.uint8))\n",
        "  bb = io.BytesIO()\n",
        "  inpainted.save(bb, 'jpeg')\n",
        "  im_bytes = bb.getvalue()\n",
        "  return anvil.BlobMedia(\"image/jpg\",im_bytes)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Manually run the final step"
      ],
      "metadata": {
        "id": "kBmqbiJMD7aZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b = #Add here the bomber num\n",
        "create_cur_mask(b)"
      ],
      "metadata": {
        "id": "Aj29VGnUOjMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/gdrive/MyDrive/Colab_Notebooks/Final_project/lama') ##to_change\n",
        "shutil.rmtree('./data_for_prediction', ignore_errors=True)\n",
        "os.mkdir('./data_for_prediction')\n",
        "img_path = '/content/gdrive/MyDrive/Colab_Notebooks/Final_project/data_for_prediction/test.jpg'##to_change\n",
        "img_name = os.path.basename(img_path)\n",
        "copyfile(img_path, f'./data_for_prediction/{img_name}')\n",
        "img = Image.open(img_path)\n",
        "mask_path = '/content/gdrive/MyDrive/Colab_Notebooks/Final_project/data_for_prediction/test_mask.png'##to_change\n",
        "mask = Image.open(mask_path)\n",
        "mask_name = f'{os.path.splitext(img_name)[0]}_mask.png'\n",
        "copyfile(mask_path, f'./data_for_prediction/{mask_name}')\n",
        "img_name = os.path.splitext(img_name)[0]\n",
        "mask_name = os.path.splitext(mask_name)[0]\n",
        "img = np.array(img)[:,:,::-1] # Convert from RGB to BGR for OpenCV\n",
        "mask = np.array(mask)\n",
        "!PYTHONPATH=. TORCH_HOME=$(pwd) python3 bin/predict.py model.path=$(pwd)/big-lama indir=$(pwd)/data_for_prediction outdir=/content/output dataset.img_suffix=.jpg\n",
        "shutil.rmtree('./data_for_prediction', ignore_errors=True)\n",
        "inpainted_path = os.path.join('/content/output', 'test_mask.png')\n",
        "inpainted = np.array(Image.open(inpainted_path).convert('RGB'))\n",
        "inpainted = Image.fromarray(inpainted.astype(np.uint8))"
      ],
      "metadata": {
        "id": "ocdNGVvVy9xZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
